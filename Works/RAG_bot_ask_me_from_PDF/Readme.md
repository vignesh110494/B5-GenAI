# RAG App -- Ask Your PDF Anything

## ğŸš€ Overview

This is a Retrieval-Augmented Generation (RAG) application built using:

-   **Streamlit** (UI)
-   **LangChain (LCEL architecture)**
-   **FAISS** (Vector database)
-   **OpenAI GPT-4.1 Mini**
-   **OpenAI Embeddings (text-embedding-3-small)**

The application allows users to:

-   Upload a PDF file\
-   Ask questions about the document\
-   Receive AI-generated answers based only on the uploaded document

------------------------------------------------------------------------

## ğŸ—ï¸ Architecture

    User Uploads PDF
            â†“
    Extract Text (PyPDF2)
            â†“
    Text Splitting (RecursiveCharacterTextSplitter)
            â†“
    Embeddings (text-embedding-3-small)
            â†“
    FAISS Vector Store
            â†“
    Retriever
            â†“
    GPT-4.1-mini
            â†“
    Answer Displayed in Streamlit

------------------------------------------------------------------------

## ğŸ“¦ Tech Stack

  Component      Technology
  -------------- ------------------------
  UI             Streamlit
  LLM            GPT-4.1-mini
  Embeddings     text-embedding-3-small
  Vector Store   FAISS
  Framework      LangChain (LCEL)
  PDF Reader     PyPDF2

------------------------------------------------------------------------

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the Repository

``` bash
git clone <your-repo-url>
cd <project-folder>
```

### 2ï¸âƒ£ Create Virtual Environment

**Windows:**

``` bash
python -m venv ragenv
ragenv\Scripts\activate
```

**Mac/Linux:**

``` bash
python3 -m venv ragenv
source ragenv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies

``` bash
pip install streamlit
pip install langchain langchain-core langchain-community
pip install langchain-openai
pip install langchain-text-splitters
pip install faiss-cpu
pip install PyPDF2
pip install python-dotenv
```

------------------------------------------------------------------------

## ğŸ” Environment Variables

Create a `.env` file in your project root:

    OPENAI_API_KEY=your_openai_api_key_here

------------------------------------------------------------------------

## â–¶ï¸ Run the Application

``` bash
streamlit run demo.py
```

Then open the URL shown in your browser (usually http://localhost:8501).

------------------------------------------------------------------------

## ğŸ§  How It Works

### 1ï¸âƒ£ PDF Upload

User uploads a text-based PDF.

> âš ï¸ Note: Scanned PDFs (image-based) will not work unless OCR is
> applied.

### 2ï¸âƒ£ Text Extraction

``` python
PdfReader(uploaded_file)
```

### 3ï¸âƒ£ Text Splitting

    chunk_size=1000
    chunk_overlap=200

This improves retrieval accuracy.

### 4ï¸âƒ£ Embeddings

Each chunk is converted into vectors using:

    text-embedding-3-small

### 5ï¸âƒ£ Vector Store (FAISS)

The embeddings are stored in FAISS for fast similarity search.

### 6ï¸âƒ£ Retrieval + LLM (RAG)

When a user asks a question:

-   Relevant chunks are retrieved\
-   Context is injected into the prompt\
-   GPT-4.1-mini generates the answer

#### LCEL Chain:

``` python
rag_chain = (
    {
        "context": retriever,
        "question": RunnablePassthrough()
    }
    | prompt
    | llm
    | StrOutputParser()
)
```

------------------------------------------------------------------------

## ğŸ“Œ Features

âœ” Upload any text-based PDF\
âœ” Automatic text chunking\
âœ” Semantic search with FAISS\
âœ” GPT-4.1-mini powered answers\
âœ” Clean Streamlit UI\
âœ” Error handling for scanned PDFs

------------------------------------------------------------------------

## ğŸ“„ License

This project is for educational and demonstration purposes.
